'max(x)',
'sd(x^2)')))
install.packages("patchwork")
# Set code chunk defaults
# Consider adding `message = FALSE` option
knitr::opts_chunk$set(echo = FALSE, warning = TRUE, message = FALSE)
# Set R environment options
options(knitr.kable.NA = '')
#load packages
library(tidyverse)
library(dplyr)
library(tidyr)
library(mclust)
library(ggrepel)
library(broom)
library(dygraphs)
library(xts)
library(lubridate)
library(plotly)
library(plyr)
library(stringr)
library(sf)
library(wordcloud2)
library(textdata)
library(tidytext)
library(glue)
library(ggplot2)
library(scales)
library(vtable)
library(patchwork)
#load data
load("final_data/blog_data.RData")
data("stop_words")
#customise stop words
custom_stop_words <-
c("https", "t.co", "openai", "ai", "artificialintelligence", "http", "gpt", "gpt4", "nannannannannew", "t", "chatgpt", "amp")
stop_words <-
stop_words %>%
bind_rows(data_frame(word = custom_stop_words))
plot1 <- tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c('mean(x)',
'median(x)',
'min(x)',
'max(x)',
'sd(x^2)'))) +
ggtitle("Summary of Followers, Friends and Favourites")
plot1 <- tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c('mean(x)',
'median(x)',
'min(x)',
'max(x)',
'sd(x^2)')))
plot2 <- tweets_df %>%
dplyr::count(user_verified) %>%
drop_na() %>%
ggplot(aes(x = "User verified", y = n, fill = user_verified)) +
geom_bar(stat = "identity") +
labs(x = "User verified", y = "Count",
title = "Distribution of Verified and Unverified Users") +
scale_fill_brewer(palette = "Dark2") +
coord_polar(theta = "y") +
theme_void() +
ggtitle("Distribution of Verified and Unverified Users")
# arrange plots side by side
plot1 + plot2 + plot_layout(ncol = 2)
plot1 <- tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c('mean(x)',
'median(x)',
'min(x)',
'max(x)',
'sd(x^2)')))
plot2 <- tweets_df %>%
dplyr::count(user_verified) %>%
drop_na() %>%
ggplot(aes(x = "User verified", y = n, fill = user_verified)) +
geom_bar(stat = "identity") +
labs(x = "User verified", y = "Count",
title = "Distribution of Verified and Unverified Users") +
scale_fill_brewer(palette = "Dark2") +
coord_polar(theta = "y") +
theme_void()
# arrange plots side by side
plot1 + plot2 + plot_layout(ncol = 2)
# Set code chunk defaults
# Consider adding `message = FALSE` option
knitr::opts_chunk$set(echo = FALSE, warning = TRUE, message = FALSE)
# Set R environment options
options(knitr.kable.NA = '')
#load packages
library(tidyverse)
library(dplyr)
library(tidyr)
library(mclust)
library(ggrepel)
library(broom)
library(dygraphs)
library(xts)
library(lubridate)
library(plotly)
library(plyr)
library(stringr)
library(sf)
library(wordcloud2)
library(textdata)
library(tidytext)
library(glue)
library(ggplot2)
library(scales)
library(vtable)
library(patchwork)
#load data
load("final_data/blog_data.RData")
data("stop_words")
#customise stop words
custom_stop_words <-
c("https", "t.co", "openai", "ai", "artificialintelligence", "http", "gpt", "gpt4", "nannannannannew", "t", "chatgpt", "amp")
stop_words <-
stop_words %>%
bind_rows(data_frame(word = custom_stop_words))
plot1 <- tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c('mean(x)',
'median(x)',
'min(x)',
'max(x)',
'sd(x^2)')))
plot2 <- tweets_df %>%
dplyr::count(user_verified) %>%
drop_na() %>%
ggplot(aes(x = "User verified", y = n, fill = user_verified)) +
geom_bar(stat = "identity") +
labs(x = "User verified", y = "Count",
title = "Distribution of Verified and Unverified Users") +
scale_fill_brewer(palette = "Dark2") +
coord_polar(theta = "y") +
theme_void()
# arrange plots side by side
plot1 + plot2 + plot_layout(ncol = 2)
tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c( 'min(x)',
'max(x)',
'mean(x)',
'median(x)',
'sd(x^2)'),
summ.names = list(
c('Min',
'Max',
'Mean',
'Median',
'SD of X^2')
)))
tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c( 'min(x)',
'max(x)',
'mean(x)',
'median(x)',
'sd(x^2)'),
summ.names = list(
c('Min',
'Max',
'Mean',
'Median',
'SD of X^2')
)))
bio_cloud
#wrangle words
bio_unigrams <-
tweets_df %>%
select(user_description) %>%
unnest_tokens(output = unigram,
input = user_description,
token = "words") %>%
anti_join(stop_words,
by = c("unigram" = "word")) %>%
select(unigram) %>%
count() %>%
filter(freq > 1000)
set.seed(1234)
bio_unigrams <-
bio_unigrams %>%
drop_na()
#creating a word cloud
bio_cloud <-
wordcloud2(data = bio_unigrams,
fontFamily = "Roboto",
fontWeight = "normal",
color  = "random-dark",
size = 0.45,
rotateRatio = 0.15,
maxRotation = 1.57,
minRotation = 1.57)
bio_cloud
#wrangle words
hashtag_unigrams <-
tweets_df %>%
select(hashtags) %>%
unnest_tokens(output = unigram,
input = hashtags,
token = "words") %>%
anti_join(stop_words,
by = c("unigram" = "word")) %>%
select(unigram) %>%
count() %>%
filter(freq > 100)
hashtag_unigrams <-
hashtag_unigrams %>%
drop_na()
set.seed(1234)
#creating a word cloud
hash_cloud <-
wordcloud2(data = hashtag_unigrams,
fontFamily = "Roboto",
fontWeight = "normal",
color  = "random-dark",
size = 0.45,
rotateRatio = 0.15,
maxRotation = 1.57,
minRotation = 1.57)
hash_cloud
# Set code chunk defaults
# Consider adding `message = FALSE` option
knitr::opts_chunk$set(echo = FALSE, warning = TRUE, message = FALSE)
# Set R environment options
options(knitr.kable.NA = '')
#load packages
library(tidyverse)
library(dplyr)
library(tidyr)
library(mclust)
library(ggrepel)
library(broom)
library(dygraphs)
library(xts)
library(lubridate)
library(plotly)
library(plyr)
library(stringr)
library(sf)
library(wordcloud2)
library(textdata)
library(tidytext)
library(glue)
library(ggplot2)
library(scales)
library(vtable)
library(patchwork)
#load data
load("final_data/blog_data.RData")
data("stop_words")
#customise stop words
custom_stop_words <-
c("https", "t.co", "openai", "ai", "artificialintelligence", "http", "gpt", "gpt4", "nannannannannew", "t", "chatgpt", "amp")
stop_words <-
stop_words %>%
bind_rows(data_frame(word = custom_stop_words))
tweets_df %>%
dplyr::count(user_verified) %>%
drop_na() %>%
ggplot(aes(x = "User verified", y = n, fill = user_verified)) +
geom_bar(stat = "identity") +
labs(x = "User verified", y = "Count",
title = "Distribution of Verified and Unverified Users") +
scale_fill_brewer(palette = "Dark2") +
coord_polar(theta = "y") +
theme_void()
tweets_df %>%
select(user_followers,
user_friends,
user_favourites) %>%
dplyr::rename("followers" = "user_followers",
"friends" = "user_friends",
"favourites" = "user_favourites") %>%
st( summ = list(c( 'min(x)',
'max(x)',
'mean(x)',
'median(x)'),
summ.names = list(
c('Min',
'Max',
'Mean',
'Median'))))
#wrangle words
bio_unigrams <-
tweets_df %>%
select(user_description) %>%
unnest_tokens(output = unigram,
input = user_description,
token = "words") %>%
anti_join(stop_words,
by = c("unigram" = "word")) %>%
select(unigram) %>%
count() %>%
filter(freq > 1000)
set.seed(1234)
bio_unigrams <-
bio_unigrams %>%
drop_na()
#creating a word cloud
bio_cloud <-
wordcloud2(data = bio_unigrams,
fontFamily = "Roboto",
fontWeight = "normal",
color  = "random-dark",
size = 0.45,
rotateRatio = 0.15,
maxRotation = 1.57,
minRotation = 1.57)
bio_cloud
#wrangle words
hashtag_unigrams <-
tweets_df %>%
select(hashtags) %>%
unnest_tokens(output = unigram,
input = hashtags,
token = "words") %>%
anti_join(stop_words,
by = c("unigram" = "word")) %>%
select(unigram) %>%
count() %>%
filter(freq > 100)
hashtag_unigrams <-
hashtag_unigrams %>%
drop_na()
set.seed(1234)
#creating a word cloud
hash_cloud <-
wordcloud2(data = hashtag_unigrams,
fontFamily = "Roboto",
fontWeight = "normal",
color  = "random-dark",
size = 0.45,
rotateRatio = 0.15,
maxRotation = 1.57,
minRotation = 1.57)
hash_cloud
#wrangle words
tweet_unigrams <-
tweets_df %>%
select(text) %>%
unnest_tokens(output = unigram,
input = text,
token = "words") %>%
anti_join(stop_words,
by = c("unigram" = "word"))%>%
select(unigram) %>%
count() %>%
filter(freq > 1000)
set.seed(1234)
tweet_unigrams <-
tweet_unigrams %>%
drop_na()
#creating   a word cloud
tweet_cloud <-
wordcloud2(data = tweet_unigrams,
fontFamily = "Roboto",
fontWeight = "normal",
color  = "random-dark",
size = 0.45,
rotateRatio = 0.15,
maxRotation = 1.57,
minRotation = 1.57)
tweet_cloud
# Summarize sentiment counts
sentiment_counts <-
tweets_df %>%
select(sentiment_label) %>%
count()
sentiment_range <-
tweets_df %>%
select(sentiment_score) %>%
count()
# Create a bar plot
g1 <-
ggplot() +
geom_bar(data = sentiment_counts,
aes(x = sentiment_label,
y = freq,
fill = sentiment_label),
stat = "identity",
width = 0.2) +
labs(x = "Sentiment",
y = "Count",
title = "Sentiment Distribution of Tweets") +
scale_fill_brewer(palette = "Dark2") +
theme_light() +
theme(axis.text.x = element_text(size = 10,
angle = 0,
color = "black",
vjust = 1,
hjust = 1),
plot.caption = element_text(hjust = 0.5))
g1
# Convert the "created_at" column to a date-time object
tweets_df$date <- as.POSIXct(tweets_df$date, format = "%Y-%m-%d %H:%M:%S")
# Group by date and count the number of tweets per day
tweets_per_day <-
tweets_df %>%
mutate(date_of_tweet = as.Date(date, format = "%m/%d/%Y")) %>%
group_by(date_of_tweet) %>%
dplyr::summarize(total_tweets = n())
tweets_per_day <-
tweets_per_day %>%
drop_na()
# Convert the data to a time series object
tweets_ts <-
xts(tweets_per_day$total_tweets,
tweets_per_day$date_of_tweet)
# Create a dygraph
tweet_day_graph <-
dygraph(tweets_ts,
main = "Frequency of Tweets Over Time") %>%
dyAxis("y", label = "Number of Tweets") %>%
dyRangeSelector() %>%
dyHighlight(highlightCircleSize = 5,
highlightSeriesOpts = list(strokeWidth = 2)) %>%
dyOptions(colors = RColorBrewer::brewer.pal(8,
"Dark2"))
tweet_day_graph
# Convert the "created_at" column to a date-time object
tweets_df$date <- as.POSIXct(tweets_df$date, format = "%Y-%m-%d %H:%M:%S")
# Group by date and count the number of tweets per day
tweets_by_day <-
tweets_df %>%
mutate(date_of_tweet = as.Date(date, format = "%m/%d/%Y")) %>%
group_by(date_of_tweet) %>%
dplyr::summarise(total_tweets = n())
tweets_by_day <-
tweets_by_day %>%
drop_na()
tweets_cumulative <-
tweets_by_day %>%
mutate(cumulative_tweets = cumsum(total_tweets))
tweets_by_month <-
tweets_by_day %>%
mutate(month = lubridate::floor_date(date_of_tweet,
'month')) %>%
group_by(month) %>%
dplyr::summarise(tweet_number = sum(as.numeric(total_tweets)))
# convert tweet data to time series objects
tweet_ts <-
xts(tweets_by_day$total_tweets,
tweets_by_day$date_of_tweet)
tweets_cumulative_ts <-
xts(tweets_cumulative$cumulative_tweets,
tweets_cumulative$date_of_tweet)
tweets_by_month_ts <-
xts(tweets_by_month$tweet_number,
tweets_by_month$month)
# create data frame for dygraph
tweet_data <- data.frame(date = tweets_by_day$date_of_tweet,
count = tweets_by_day$total_tweets)
# `cbind` tweet data with month data (this allows us to create
# timeseries graphs with multiple data sets
tweet_prime <-
cbind(tweet_ts, tweets_cumulative_ts, tweets_by_month_ts)
tweet_date_graph <-
dygraph(tweet_prime,
main = "Tweets by Date",
group = "timeseries") %>%
dySeries("tweet_ts",
label = "tweets this day") %>%
dySeries('tweets_by_month_ts',
label = "tweets this month") %>%
dySeries("tweets_cumulative_ts",
label = "tweets to date") %>%
dyOptions(colors = RColorBrewer::brewer.pal(8, "Dark2"),
connectSeparatedPoints = TRUE,
fillGraph = TRUE,
fillAlpha = 0.3) %>%
dyLegend(width = 400) %>%
dyRangeSelector() %>%
dyAxis("y", label = "tweet count")
tweet_date_graph
# automatically create a bib database for R packages
knitr::write_bib(
c(.packages(), 'knitr', 'rmarkdown'),
'packages.bib')#
